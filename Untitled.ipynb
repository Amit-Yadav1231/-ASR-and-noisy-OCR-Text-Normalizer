{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amit-Yadav1231/-ASR-and-noisy-OCR-Text-Normalizer/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b1d4ff14-e3e5-4934-ad38-69865855751d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1d4ff14-e3e5-4934-ad38-69865855751d",
        "outputId": "0227d5d8-3231-4eff-f531-f4f697183175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from nltk.corpus import brown\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d87eda47-67fb-4d56-8f73-acc4bf2e3cd5",
      "metadata": {
        "id": "d87eda47-67fb-4d56-8f73-acc4bf2e3cd5"
      },
      "outputs": [],
      "source": [
        "# sentences = brown.sents()\n",
        "# sentences = [' '.join(s).lower() for s in sentences]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62ad0b31-7bc1-4992-8524-f1a371c71836",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62ad0b31-7bc1-4992-8524-f1a371c71836",
        "outputId": "cb11094c-68cb-439c-bc6c-8a6cfde6d6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57340\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import brown\n",
        "print(len(brown.sents()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bccb785f-f7a8-4a43-b1c2-f10bf2873256",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bccb785f-f7a8-4a43-b1c2-f10bf2873256",
        "outputId": "5fff9add-da9d-45f3-e2cd-8e425e64f2fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the fulton county grand jury said friday an investigation of atlantas recent primary election produced  no evidence  that any irregularities took place\n"
          ]
        }
      ],
      "source": [
        "def get_clean_sentences(limit=2000):\n",
        "    sentences = brown.sents()[:limit]\n",
        "    clean = []\n",
        "    for sent in sentences:\n",
        "        s = \" \".join(sent).lower()\n",
        "        s = re.sub(r\"[^a-z\\s]\", \"\", s)\n",
        "        clean.append(s.strip())\n",
        "    return clean\n",
        "\n",
        "clean_sentences = get_clean_sentences()\n",
        "print(clean_sentences[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e4866d2e-bb2f-4505-b806-4b2d72a1c72d",
      "metadata": {
        "id": "e4866d2e-bb2f-4505-b806-4b2d72a1c72d"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(clean_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5bcbcda1-c7e2-41c2-9c8e-851d44896b30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bcbcda1-c7e2-41c2-9c8e-851d44896b30",
        "outputId": "85d1688b-3fad-4b55-e599-031df04fe10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words: 6893\n"
          ]
        }
      ],
      "source": [
        "word_index = tokenizer.word_index\n",
        "print(\"Total unique words:\", len(word_index))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aea44572-6b36-44b5-b82e-d19dde738893",
      "metadata": {
        "id": "aea44572-6b36-44b5-b82e-d19dde738893"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "\n",
        "for sentence in clean_sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        sequences.append(token_list[:i+1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fd9c815f-b5df-4d10-a5ec-ed2def881060",
      "metadata": {
        "id": "fd9c815f-b5df-4d10-a5ec-ed2def881060"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1ec47ccc-4ace-4814-95c5-a0a9153cbbb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ec47ccc-4ace-4814-95c5-a0a9153cbbb2",
        "outputId": "45117a2e-ba37-4876-881c-44aefb8c5046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6894\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary size:\", vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0dcfe1d6-05e7-43e2-a937-62db58d79ace",
      "metadata": {
        "id": "0dcfe1d6-05e7-43e2-a937-62db58d79ace"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "813b3ae6-86b6-4790-9d7f-0f1039b6bbf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "813b3ae6-86b6-4790-9d7f-0f1039b6bbf3",
        "outputId": "3337132d-637c-405c-cc8f-075b602c5d7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m689,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6894\u001b[0m)           │     \u001b[38;5;34m1,040,994\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">689,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6894</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040,994</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,880,994\u001b[0m (7.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,880,994</span> (7.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,880,994\u001b[0m (7.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,880,994</span> (7.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(max_len-1,)),\n",
        "    Embedding(input_dim=vocab_size, output_dim=100),\n",
        "    LSTM(150),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7cac22de-2a05-42cd-af2c-cfc116589a3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cac22de-2a05-42cd-af2c-cfc116589a3d",
        "outputId": "a9b79a75-6280-4d0f-9fff-851a15b44b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 200ms/step - accuracy: 0.0692 - loss: 7.5242\n",
            "Epoch 2/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 202ms/step - accuracy: 0.0888 - loss: 6.7567\n",
            "Epoch 3/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 200ms/step - accuracy: 0.1026 - loss: 6.4057\n",
            "Epoch 4/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 200ms/step - accuracy: 0.1180 - loss: 6.0768\n",
            "Epoch 5/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 200ms/step - accuracy: 0.1340 - loss: 5.7408\n",
            "Epoch 6/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 201ms/step - accuracy: 0.1471 - loss: 5.3936\n",
            "Epoch 7/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 201ms/step - accuracy: 0.1590 - loss: 5.1034\n",
            "Epoch 8/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 201ms/step - accuracy: 0.1767 - loss: 4.8272\n",
            "Epoch 9/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 200ms/step - accuracy: 0.1971 - loss: 4.5510\n",
            "Epoch 10/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 206ms/step - accuracy: 0.2221 - loss: 4.2726\n",
            "Epoch 11/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 201ms/step - accuracy: 0.2564 - loss: 4.0288\n",
            "Epoch 12/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 201ms/step - accuracy: 0.2923 - loss: 3.7720\n",
            "Epoch 13/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 202ms/step - accuracy: 0.3321 - loss: 3.5240\n",
            "Epoch 14/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 205ms/step - accuracy: 0.3743 - loss: 3.2732\n",
            "Epoch 15/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 198ms/step - accuracy: 0.4124 - loss: 3.0453\n",
            "Epoch 16/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 199ms/step - accuracy: 0.4505 - loss: 2.8539\n",
            "Epoch 17/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 198ms/step - accuracy: 0.4858 - loss: 2.6503\n",
            "Epoch 18/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 197ms/step - accuracy: 0.5176 - loss: 2.4597\n",
            "Epoch 19/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 198ms/step - accuracy: 0.5545 - loss: 2.2867\n",
            "Epoch 20/20\n",
            "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 197ms/step - accuracy: 0.5814 - loss: 2.1490\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f0607ee3-f975-48ec-b1eb-3f126ed75510",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0607ee3-f975-48ec-b1eb-3f126ed75510",
        "outputId": "014e6175-6212-4a77-d902-245ef238eaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['accuracy', 'loss'])\n"
          ]
        }
      ],
      "source": [
        "print(history.history.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6b7e2725-8fd6-4489-9463-295c076abe63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b7e2725-8fd6-4489-9463-295c076abe63",
        "outputId": "57cd5c1c-3f3b-4d6b-d9ab-ff5af071bd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 2.2224955558776855\n",
            "Final accuracy: 0.5616441965103149\n"
          ]
        }
      ],
      "source": [
        "print(\"Final loss:\", history.history['loss'][-1])\n",
        "print(\"Final accuracy:\", history.history['accuracy'][-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a7f0483c-cee6-4971-aa24-30826a4a1135",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7f0483c-cee6-4971-aa24-30826a4a1135",
        "outputId": "b8148906-6367-47bc-d002-18039c5addcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6893\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenizer.word_index))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5d5ac243-116f-4340-b6f4-b838ed0d9870",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d5ac243-116f-4340-b6f4-b838ed0d9870",
        "outputId": "e7de58bb-2f24-4016-a4c7-1e8b96e9e97c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n"
          ]
        }
      ],
      "source": [
        "print(max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1c5a424c-2d39-4bb0-b509-8e3529d3b485",
      "metadata": {
        "id": "1c5a424c-2d39-4bb0-b509-8e3529d3b485"
      },
      "outputs": [],
      "source": [
        "def generate_text(seed_text, next_words=10):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0))\n",
        "\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                seed_text += \" \" + word\n",
        "                break\n",
        "    return seed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5aff1d23-c9d2-4fe9-a2a2-df13a244d6b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aff1d23-c9d2-4fe9-a2a2-df13a244d6b1",
        "outputId": "80630fdb-dac4-46a4-d18c-20dc6e4d6cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the government is the first of the sixth which will be an\n",
            "he was a graduate of ucla and perkins school of theology aj college has\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(\"the government\", 10))\n",
        "print(generate_text(\"he was\", 12))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9d5693f4-1fd5-40a7-b192-55e6ae9ea55f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d5693f4-1fd5-40a7-b192-55e6ae9ea55f",
        "outputId": "ee4e9029-4cba-4962-d508-492982cd9d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"language_model_lstm.h5\")\n",
        "model.save(\"language_model_lstm.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e54bb77c-337d-4c28-9fe0-2c4f2c353c29",
      "metadata": {
        "id": "e54bb77c-337d-4c28-9fe0-2c4f2c353c29"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"tokenizer_lm.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e0166156-0030-4dfb-9344-da906b2a64e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0166156-0030-4dfb-9344-da906b2a64e1",
        "outputId": "e9abcf0b-f644-4d02-919e-4381e76d0a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-1 Language Model & Tokenizer saved successfully.\n"
          ]
        }
      ],
      "source": [
        "print(\"Step-1 Language Model & Tokenizer saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5fb0acf7-1fa5-4bc2-bf6d-888c2f68ff0e",
      "metadata": {
        "id": "5fb0acf7-1fa5-4bc2-bf6d-888c2f68ff0e"
      },
      "outputs": [],
      "source": [
        "# def sample_with_temperature(preds, temperature=0.8):\n",
        "#     preds = np.asarray(preds).astype('float64')\n",
        "#     preds = np.log(preds + 1e-8) / temperature\n",
        "#     exp_preds = np.exp(preds)\n",
        "#     preds = exp_preds / np.sum(exp_preds)\n",
        "#     return np.random.choice(len(preds), p=preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fc61cc9a-a653-4384-92f8-6cd6283895c3",
      "metadata": {
        "id": "fc61cc9a-a653-4384-92f8-6cd6283895c3"
      },
      "outputs": [],
      "source": [
        "# def generate_text(seed_text, next_words=10, temperature = 0.8):\n",
        "#     for _ in range(next_words):\n",
        "#         token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "#         token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "#         preds = model.predict(token_list, verbose=0)[0]\n",
        "#         predicted = sample_with_temperature(preds, temperature)\n",
        "\n",
        "\n",
        "#         for word, index in tokenizer.word_index.items():\n",
        "#             if index == predicted:\n",
        "#                 seed_text += \" \" + word\n",
        "#                 break\n",
        "#     return seed_text\n",
        "# #  AGAR HM ES FUNCTIION KA US EKR RAHE HAI TO HAME kuchh random words mil rahe hai HIGH PROBABILITY WALE KE ALAWA BHI KISI KO CONSIDER KR LE RHA HAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0f4447c6-2556-4669-80a6-48162732c768",
      "metadata": {
        "id": "0f4447c6-2556-4669-80a6-48162732c768"
      },
      "outputs": [],
      "source": [
        "# print(generate_text(\"the government\", 15, temperature=0.7))\n",
        "# print(generate_text(\"the government\", 15, temperature=1.0))\n",
        "# print(generate_text(\"the government\", 15, temperature=1.2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9a1a9102-e229-45ce-af0a-09f510fdae41",
      "metadata": {
        "id": "9a1a9102-e229-45ce-af0a-09f510fdae41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "25dc7cae-1822-4acd-8585-5bc11681d827",
      "metadata": {
        "id": "25dc7cae-1822-4acd-8585-5bc11681d827"
      },
      "outputs": [],
      "source": [
        "# #  MUST be written AFTER tokenization & padding\n",
        "# vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# model = Sequential([\n",
        "#     Embedding(\n",
        "#         input_dim=vocab_size,\n",
        "#         output_dim=64,\n",
        "#         input_length=max_len\n",
        "#     ),\n",
        "#     Bidirectional(LSTM(128, return_sequences=True)),\n",
        "#     Dense(vocab_size, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss='sparse_categorical_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# # model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8990a7f5-48e9-4700-abf1-63c9c3710a42",
      "metadata": {
        "id": "8990a7f5-48e9-4700-abf1-63c9c3710a42"
      },
      "outputs": [],
      "source": [
        "# print(\"Vocab size:\", vocab_size)\n",
        "# print(\"Max sequence length:\", max_len)\n",
        "# print(\"X_train shape:\", X_train.shape)\n",
        "# print(\"y_train shape:\", y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2f61693d-2f18-4a89-aff2-907688f9b800",
      "metadata": {
        "id": "2f61693d-2f18-4a89-aff2-907688f9b800"
      },
      "outputs": [],
      "source": [
        "# y_train = np.expand_dims(y_train, -1)\n",
        "# y_test = np.expand_dims(y_test, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "15dc6317-1bff-4f87-a41e-d825244bed7e",
      "metadata": {
        "id": "15dc6317-1bff-4f87-a41e-d825244bed7e"
      },
      "outputs": [],
      "source": [
        "# indices = np.arange(len(X_train))\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# X_train = X_train[indices]\n",
        "# y_train = y_train[indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b5e69a5a-8b0c-4fae-ad6e-120c6a9f0b29",
      "metadata": {
        "id": "b5e69a5a-8b0c-4fae-ad6e-120c6a9f0b29"
      },
      "outputs": [],
      "source": [
        "# model = Sequential([\n",
        "#     Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64),\n",
        "#     Bidirectional(LSTM(128, return_sequences=True)),\n",
        "#     Dense(len(tokenizer.word_index)+1, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss='sparse_categorical_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "23c0ab0e-aeb0-48d2-83cb-16c93f3a74b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23c0ab0e-aeb0-48d2-83cb-16c93f3a74b6",
        "outputId": "56cb32ec-1518-466a-a9e2-96969bccec11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "normalizer = load_model(\"language_model_lstm.keras\")\n",
        "\n",
        "with open(\"tokenizer_lm.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "MAX_LEN = normalizer.input_shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# reverse mapping\n",
        "inv_vocab = {v: k for k, v in tokenizer.word_index.items()}\n",
        "\n",
        "def normalize_word(word):\n",
        "    seq = tokenizer.texts_to_sequences([word])[0]\n",
        "    if len(seq) == 0:\n",
        "        return word  # unknown word\n",
        "\n",
        "    seq = pad_sequences([seq], maxlen=MAX_LEN, padding=\"post\")\n",
        "    pred = normalizer.predict(seq, verbose=0)\n",
        "    pred_id = int(np.argmax(pred, axis=-1)[0])\n",
        "\n",
        "    return inv_vocab.get(pred_id, word)\n"
      ],
      "metadata": {
        "id": "voqv4Z3GlYqc"
      },
      "id": "voqv4Z3GlYqc",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_sentence(sentence):\n",
        "    words = re.findall(r\"\\b\\w+\\b\", sentence.lower())\n",
        "    corrected = [normalize_word(w) for w in words]\n",
        "    return \" \".join(corrected)\n"
      ],
      "metadata": {
        "id": "Hzc65XwOlYdu"
      },
      "id": "Hzc65XwOlYdu",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    \"da goverment anounced new polic\",\n",
        "    \"he waz not aware of the decison\",\n",
        "    \"this is smple tst\"\n",
        "]\n",
        "\n",
        "for s in samples:\n",
        "    print(\"Noisy :\", s)\n",
        "    print(\"Clean :\", normalize_sentence(s))\n",
        "    print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oii7q79xlnIl",
        "outputId": "9e5a9bca-35ea-4b5a-ee58-3381f4441899"
      },
      "id": "oii7q79xlnIl",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noisy : da goverment anounced new polic\n",
            "Clean : da goverment anounced a polic\n",
            "----\n",
            "Noisy : he waz not aware of the decison\n",
            "Clean : a waz a aware a a decison\n",
            "----\n",
            "Noisy : this is smple tst\n",
            "Clean : a a smple tst\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inv_vocab = {v: k for k, v in tokenizer.word_index.items()}\n"
      ],
      "metadata": {
        "id": "YGoD9DsEkd7J"
      },
      "id": "YGoD9DsEkd7J",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cpnhu3Qikqpc"
      },
      "id": "Cpnhu3Qikqpc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dm4MNK9pkqd8"
      },
      "id": "dm4MNK9pkqd8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvp-b7T_kde5"
      },
      "id": "vvp-b7T_kde5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper sounddevice scipy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp1GFS9vOZcH",
        "outputId": "4f40f0c7-5413-4ad3-c399-d96df09ad307"
      },
      "id": "Vp1GFS9vOZcH",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/803.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Collecting triton>=2 (from openai-whisper)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Downloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=be27e7213783cc28439c8330b6b42614f05f64f3fc723b6657f3233e02544f0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, sounddevice, openai-whisper\n",
            "Successfully installed openai-whisper-20250625 sounddevice-0.5.3 triton-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "asr_model = whisper.load_model(\"base\")\n",
        "\n",
        "def speech_to_corrected_text(audio_path):\n",
        "    result = asr_model.transcribe(audio_path)\n",
        "    raw_text = result[\"text\"]\n",
        "    clean_text = normalize_sentencet(raw_text)\n",
        "    return clean_text\n"
      ],
      "metadata": {
        "id": "jlbaRRyGPOfU"
      },
      "id": "jlbaRRyGPOfU",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sounddevice scipy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph4LzPXqQnFX",
        "outputId": "a666e566-e31b-4b26-d9a7-34ae62deb649"
      },
      "id": "Ph4LzPXqQnFX",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "def record_audio(filename=\"input.wav\", duration=5, fs=16000):\n",
        "    print(\"Recording...\")\n",
        "    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
        "    sd.wait()\n",
        "    write(filename, fs, audio)\n",
        "    print(\"Saved to\", filename)\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "hkEymZcoRacE"
      },
      "id": "hkEymZcoRacE",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "r84Ffchyen7G",
        "outputId": "4c245865-1fc0-4e77-bb34-e3dc4863838a"
      },
      "id": "r84Ffchyen7G",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m689,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6894\u001b[0m)           │     \u001b[38;5;34m1,040,994\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">689,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6894</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040,994</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,761,990\u001b[0m (14.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,761,990</span> (14.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,880,994\u001b[0m (7.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,880,994</span> (7.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,880,996\u001b[0m (7.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,880,996</span> (7.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer.save(\"final_word_normalizer.keras\")\n",
        "\n",
        "import pickle\n",
        "with open(\"final_tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n"
      ],
      "metadata": {
        "id": "L7uToI-Otz_3"
      },
      "id": "L7uToI-Otz_3",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checkpoint saved: ASR + Word Normalizer ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDaaj-eAt81T",
        "outputId": "ac971b1d-43da-4ae6-b69b-4acc14baa6a7"
      },
      "id": "nDaaj-eAt81T",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: ASR + Word Normalizer ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQO92LR3t_jS"
      },
      "id": "RQO92LR3t_jS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}